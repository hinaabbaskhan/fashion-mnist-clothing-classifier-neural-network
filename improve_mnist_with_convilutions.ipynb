{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hinaabbaskhan/fashion-mnist-clothing-classifier-neural-network/blob/main/improve_mnist_with_convilutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQjHqsmTAVLU"
      },
      "source": [
        "# Improve MNIST with Convolutions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZpztRwBouwYp",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq5S6z0vLmf9"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Begin by loading the data.\n",
        "\n",
        "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
        "\n",
        "- `load_data` returns the train and test sets in the form of the tuples `(x_train, y_train), (x_test, y_test)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "ztD3ndy4Lmf-"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdoKYWEJLmf-"
      },
      "source": [
        "## Pre-processing the data\n",
        "\n",
        "One important step when dealing with image data is to preprocess the data. During the preprocess step we apply transformations to the dataset that will be fed into our convolutional neural network.\n",
        "\n",
        "Here we will apply two transformations to the data:\n",
        "- Reshape the data so that it has an extra dimension. The reason for this is that commonly we use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
        "\n",
        "\n",
        "- Normalize the pixel values so that these are values between 0 and 1. We can achieve this by dividing every value in the array by the maximum.\n",
        "\n",
        "These tensors are of type `numpy.ndarray` so we can use functions like [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) or [divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) to complete the `reshape_and_normalize` function below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "jpMQHB3MLmf-"
      },
      "outputs": [],
      "source": [
        "def reshape_and_normalize(images):\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = np.reshape(images, (images.shape[0], images.shape[1], images.shape[2], 1))\n",
        "\n",
        "    # Normalize pixel values\n",
        "    images = np.divide(images,255)\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeWsAV-XLmf-",
        "outputId": "35579bc3-740c-4937-ad69-498fd5eeb0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS9-UIw6Lmf-"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Maximum pixel value after normalization: 1.0\n",
        "\n",
        "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
        "\n",
        "Shape of one image after reshaping: (28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmtBYEuXLmf-"
      },
      "source": [
        "## Defining our callback\n",
        "\n",
        "The callback will ensure that training will stop after an accuracy of 99.5% is reached:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "0oVsDgY1Lmf-"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "    # Check the loss\n",
        "    if(logs.get('accuracy') > 0.995):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\nAccuracy is greater than 0.995 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfgLWHH7Lmf_"
      },
      "source": [
        "## Convolutional Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "yyRYssqcLmf_"
      },
      "outputs": [],
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "     # Add convolutions and max pooling\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rIemtBSLmf_",
        "outputId": "d6496076-8f1f-404f-df3d-0b6ff09b48a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 39s 20ms/step - loss: 0.1498 - accuracy: 0.9549\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0501 - accuracy: 0.9851\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0322 - accuracy: 0.9902\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0200 - accuracy: 0.9937\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9956\n",
            "Accuracy is greater than 0.995 so cancelling training!\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0132 - accuracy: 0.9956\n"
          ]
        }
      ],
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XcfBnoKLmf_"
      },
      "source": [
        "If we see the message that we defined in your callback printed out after less than 10 epochs it means our callback worked as expected. We can also double check by running the following cell:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT9sXxDBLmf_",
        "outputId": "787c5f32-e9af-468f-d7dc-3cb49a6de49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our model was trained for 5 epochs\n"
          ]
        }
      ],
      "source": [
        "print(f\"Our model was trained for {len(history.epoch)} epochs\")"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}